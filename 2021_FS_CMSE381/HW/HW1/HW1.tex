% Don't touch this %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage[left=1in,top=1in,right=1in,bottom=1in,headheight=3ex,headsep=3ex]{geometry}
\usepackage{graphicx}
\usepackage{float}


\newcommand{\blankline}{\quad\pagebreak[2]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Modify Course title, instructor name, semester here %%%%%%%%

\title{\underline{CMSE 381 }}
\author{\underline{\textbf{Fall Semester 2021}}}
\date{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Don't touch this %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[sc]{mathpazo}
\linespread{1.05} % Palatino needs more leading (space between lines)
\usepackage[T1]{fontenc}
\usepackage[mmddyyyy]{datetime}% http://ctan.org/pkg/datetime
\usepackage{advdate}% http://ctan.org/pkg/advdate
\newdateformat{syldate}{\twodigit{\THEMONTH}/\twodigit{\THEDAY}}
\newsavebox{\MONDAY}\savebox{\MONDAY}{Mon}% Mon
\newcommand{\week}[2]{%
%  \cleardate{mydate}% Clear date
% \newdate{mydate}{\the\day}{\the\month}{\the\year}% Store date
  \paragraph*{\kern-2ex\quad #1, \syldate{\today} - \AdvanceDate[4]\syldate{\today}:}% Set heading  \quad #1
%  \setbox1=\hbox{\shortdayofweekname{\getdateday{mydate}}{\getdatemonth{mydate}}{\getdateyear{mydate}}}%
  \ifdim\wd1=\wd\MONDAY
    \AdvanceDate[7]
  \else
    \AdvanceDate[7]
  \fi%
}
\usepackage{setspace}
\usepackage{multicol}
%\usepackage{indentfirst}
\usepackage{fancyhdr,lastpage}
\usepackage{url}
\pagestyle{fancy}
\usepackage{hyperref}
\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{layout}

\lhead{}
\chead{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Don't touch this %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\lfoot{}
\cfoot{\small \thepage/\pageref*{LastPage}}
\rfoot{}

\usepackage{array, xcolor}
\usepackage{color,hyperref}
\definecolor{clemsonorange}{HTML}{EA6A20}
\hypersetup{colorlinks,breaklinks,linkcolor=clemsonorange,urlcolor=clemsonorange,anchorcolor=clemsonorange,citecolor=black}
\usepackage{txfonts}
\begin{document}

\maketitle

\blankline

For the coding project, you can find the data on http://www.statlearning.com/resources-first-edition.  Please write your codes using Google style.
\begin{enumerate}
	\item Exercise 2.4.7
	\item Exercise 2.4.8
	\item Load dat1.csv file from D2L, and write a Nearest neighbor prediction function in R to predict the values of $Y$ for $X = -1.9, -1.8, -1.7, \ldots, 1.8, 1.9$ with radius $r = 0.1$ or $0.3$ (namely, we define the neighborhood of a point $x$ as the interval $[x-r, x + r]$). Make a scatter plot of original data and the predicted results. Explain the difference between the two sets of result. Which one is more flexible?
	\item Exercise 2.4.10. you can find the data on http://www.statlearning.com/resources-first-edition.  Please write your codes using Google style.
	\item  What are the advantages and disadvantages of very flexible (vs less flexible) approach for regression or classification? When would be a more flexible approach preferable? What about a less-flexible approach?
	\item (Challenging problem, not required) Given nine data point in descending order $\{x_1, x_2, \ldots, x_9\}$, prove that the best point, $a$, to represent these nine data with the smallest absolute error is the median of these nine data points, which is $x_5$ . Namely, $a$ minimizes 
	\begin{align*}
	   \sum_{i = 1}^{9}|x_i - a|
\end{align*}	  
		\item For simple linear regression, we assume that $Y = \beta_0 + \beta_1 X + \epsilon$, where $\epsilon \sim N(0, \sigma^2)$ and $X$ is fixed (not random). We collect $n$ i.i.d. training sample $\{(x_1, y_1), \ldots, (x_n, y_n)\}$. Prove that the $(\hat{\beta}_0, \hat{\beta}_1)$ estimated through minimizing RSS equals to the one through maximizing likelihood. 
	\item  Using equation (3.4) in textbook, prove that in the case of simple linear regression, the least squares line always passes through the point $( \bar{x}, \bar{y})$.
		\item Exercise 3.7.8
	\item Download the Regression.csv file from D2L, and write a modified $K$Nearest Neighbor prediction function to predict the values of $Y$ 
	for $X = -2.30, -2.29, -2.28, \ldots, 2.28, 2.29, 2.30$ with
	 $ K = 1, 5, 10,$ and $25$ (namely, we define the neighborhood of a point $x$ as the $K$ points in the training set with smallest Euclidean distance to $x$, and then calculate the \textcolor{red}{median} of the observed $y$ at these points).
\begin{itemize}
	\item[a] Make a scatter plot of original training data and the predicted results (you can use 'lines' in R). 
    \item[b] Calculate the MSE for the training data and the testing data (the third column in the downloaded data) for different $K$s and plot it. (similar to Figure 2.10 in the textbook). Describe the pattern for the two MSE. What is the optimal 'K' you will choose?
\end{itemize}	
 \item Download wine.csv and 'wine.R' file from D2L. Run the scripts in wine.R to generate the training and testing sets. Write a $K$-Nearest Neighbor classifier function. 
   \begin{itemize}
   \item[a]  For $k = 1, 2,\ldots, 10, 20, 30$, calculate the training error rate and the testing error rate for different $K$s and plot it. (similar to Figure 2.17 in the textbook). Describe the pattern for the two error rates. What is the optimal 'K' you will choose?
   \item[b] For \textcolor{red}{$K = 10$}, we fix $x_2 = 4$ and vary the  $x_1$ from 10 to  30 to estimate the $P(Y = 1 | X_1 = x_1, X_2 = x_2)$.  Approximately, find out the value of $x_1$ for the decision boundary with $x_2 = 4$. 
\end{itemize}    

\end{enumerate}

\end{document}



