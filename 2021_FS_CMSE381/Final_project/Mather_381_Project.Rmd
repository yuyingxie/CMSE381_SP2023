---
title: "CMSE Project"
author: "Dylan Mather"
date: "4/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
#These are the libraries I used
library(ISLR)
library(dplyr)
library(purrr)
library(glmnet)
```
## Background
 
 There is a rising trend in accidental death by overdose in the United states and part of that problem is some medical professionals are prescribing more than 10 opioids in a year.  This heavily depends on what their specialty is and what other drugs they are prescribing.  Some of these professionals seem to be justified in their higher rate of opioids they are prescribing based on their field of work however that does not change the fact that the death toll caused by overdoses from these drugs are rising.  
 
 My main goal for this project is try an predict if a medial professional is likely to prescribe opioids more than 10 times in a year based off the other drugs they use, their specialty and the deaths per capita from drug overdose in the state they practice. I hope to identify which professions pose the greatest risk to the rising overdose epidemic as well which states need stricter policies to help begin to fix this problem we are facing in our country.  
 
 In order to answer this question I took my data from three data sets from kaggle. The main data set is the preseriber data which has information about each medical professionals' specialty, credentials, gender, state in which they practice, and a long list of drugs they prescribed in that year.  The opioids data set is simply a list of opioid drug names, and the overdoses has information about how many deaths were in each state as well as the population of that state.  I used the two smaller data sets to split the prescriber data into two categories, one that has only opioid drugs and one that has all the rest.  Additionally, I added the data from the overdose data to the main data, also adding a deaths per captia column so I could more fairly compare death in states with large differences in population sizes.   
 
 
## Related Project
https://www.kaggle.com/apryor6/detecting-frequent-opioid-prescription
 
This link will take you to the R project made by the person who posted this data on kaggle.  His way of cleaning the data was very good but I also saw some ways in which I wanted to change it. I wanted to make the two seperate data sets with opioids and without as well as adding the additional layer of deaths per capita. In his project he used a boosting method that takes very long to run and gets a decent accuracy but I decided to use a logistic regression, lasso and ridge regression models instead since they are less computationally expensive and I found they produced similar results.  



```{r, include=FALSE}
data <- read.csv("prescriber-info.csv")

head(data)
data1 = data %>%
  select(-Credentials,-NPI,-Gender)
  
#Took out Credentials since that column was a mess and not worth sorting to get the data we wanted to make pedictions
#Gender is not important when conducting the prediction
#NPI  was just the doctors ID number so not useful for making predictions.  



```

```{r,include=FALSE}
state_names <- data1%>%
  group_by(State) %>%
  dplyr::summarise(state.counts = n()) %>%
  filter(state.counts > 5) %>%
  select(State)
#state_names


data2 <- data1%>%
  filter(State %in% state_names$State)


#head(data2)

```


```{r, include=FALSE}


overdose <- read.csv("overdoses.csv")
overdose_data <- overdose %>%
  mutate(deaths.per.cap = Deaths/Population)%>%
  arrange(desc(deaths.per.cap))
#head(overdose_data)
```

```{r, echo=FALSE}
knitr::kable(head(overdose_data), "pipe", caption = "The 6 states with the higest deaths per capita")
```
While cleaning my data I made the column of the deaths per cap in order to see which state are being most affected by the opioid epidemic.  These states are most likely in need for some reform on the laws surrounding prescribing opioids in order to reduce the number of overdoses they have.

```{r, include=FALSE}
opioids <- read.csv("opioids.csv")

opioids <- as.character(opioids[,1])

```

```{r, include=FALSE}
data2 = data2 %>%
  map_if(is.character, factor)
data2 = data.frame(data2)
#head(data2)
```

```{r, include=FALSE}
# this chunk is to help sort the data in the specialties column so they can be used for the different regression tool I want to use for this project
specialties <- data2 %>%
  group_by(Specialty) %>%
  dplyr::summarise(specialty.counts = n()) %>%
  filter(specialty.counts > 40) %>%
  select(Specialty)

specialties <- levels(droplevels(specialties$Specialty))
temp <- factor(x=rep("other",nrow(data2)),levels=c(specialties,"Surgeon","other","Pain.Management"))
temp[data2$Specialty %in% specialties] <-data2$Specialty[data2$Specialty %in% specialties]
temp[grepl("surg",data2$Specialty,ignore.case=TRUE)] <- "Surgeon"
temp[grepl("pain",data2$Specialty,ignore.case=TRUE)] <-"Pain.Management"
temp <- droplevels(temp)
data2$Specialty <- temp
  
data2 %>%
  group_by(Specialty) %>%
  dplyr::summarise(specialty.counts = n()) %>%
  arrange(specialty.counts)


```

## Data
The heads of these two data sets show the cleaned data with all the added dimensions I wanted to add. They do not show all the drugs included to save space on this report. 

```{r, include=FALSE}
#This section split the data into opioid drugs and non opioid drugs so we can make different predictions with each


opioids <- gsub("\ |-",".",opioids) 
no_opioids <- data2[, !names(data2) %in% opioids]
opioids_data <- data2[, names(data2) %in% opioids]
#head(opioids_data)
opioids_data$State <- data2$State
opioids_data$Specialty <-data2$Specialty
opioids_data$Opioid.Prescriber <- data2$Opioid.Prescriber

opioids_data <- opioids_data[, c(12, 13, 1:11, 14)]
```

```{r, echo=FALSE}

knitr::kable(head(no_opioids[,c(1,2,242)]), "pipe", caption = "Data without Opioids")

```



```{r, include=FALSE}
opioids_data <- opioids_data%>%
  filter(State != "PR")%>%
  filter(State != "DC")
#took these states out so I could combine the opioid data with the prescriber data
```


```{r, include=FALSE}
opioids_overdose <- left_join(opioids_data,overdose_data,by = c("State" = "Abbrev"))
opioids_overdose<-opioids_overdose%>%
  select(-State.y)
```

```{r, echo=FALSE}
#colnames(opioids_overdose)
knitr::kable(head(opioids_overdose[,c(1,2,14,17)]), "pipe", caption = "Opioid Data with Deaths Per Capita")

```


```{r, include=FALSE}
#making the training and testing sets for the data that includes the opioid drugs
train <- sort(sample(nrow(opioids_overdose), nrow(opioids_overdose)*.7))
test_oo <- opioids_overdose[-train, ]
train_oo <- opioids_overdose[train, ]

head(train_oo)
```

## GLM Regression

I chose to use GLM regression for this project since It does well with data with large dimensionality.  This function makes a linear model that is perfect for classification problems.  I first fitted my data to predict the Prescriber column based on Specialty since I expected this to be one of the most important dimensions when predicting this value.  When assessing the summary of the fit, some of the different specialties were more influential than the others, however I was surprised to see that Family Practice was included in that list.  I think this is a red flag for this practice since its the odd one out of the other specialties since most of the others are in pain management or surgery.  The accuracy of this model was decent, having a 73% prediction rate which was worse than the project on kaggle.
```{r, include=FALSE}
fit_glm <- glm(Opioid.Prescriber ~ Specialty,data = train_oo, family = "binomial")
summary(fit_glm)
```

```{r, include=FALSE}
pred_glm <- predict(fit_glm, test_oo[, -14])
pred_glm_01 <- ifelse(pred_glm > .5, 1, 0)
glm_rmse <- (mean((pred_glm_01 - test_oo$Opioid.Prescriber)^2))^.5
glm_accuracy <- mean(pred_glm_01 == test_oo$Opioid.Prescriber)
glm_opioid1 <- data.frame(glm_accuracy,glm_rmse)
```

```{r, echo=FALSE}


knitr::kable(glm_opioid1, "pipe", caption = "Predictions based solely on Specialty")
 
knitr::kable(table(pred_glm_01, test_oo$Opioid.Prescriber), "pipe", caption = "Confusion Matrix")
```
I also wanted to look at how well my new column would predict the prescriber column.  When I ran this fit it did not work well at all, having an accuracy significantly lower than 50% which would be the prediction rate if we simply flipped a coin.  
```{r, include=FALSE}
fit_glm <- glm(Opioid.Prescriber ~ deaths.per.cap,data = train_oo, family = "binomial")
summary(fit_glm)
```

```{r, include=FALSE}
pred_glm <- predict(fit_glm, test_oo[, -14])
pred_glm_01 <- ifelse(pred_glm > .5, 1, 0)
glm_rmse <- (mean((pred_glm_01 - test_oo$Opioid.Prescriber)^2))^.5
glm_accuracy <- mean(pred_glm_01 == test_oo$Opioid.Prescriber)
glm_opioid2 <- data.frame(glm_accuracy,glm_rmse)
```

```{r, echo=FALSE}
knitr::kable(glm_opioid2, "pipe", caption = "Predictions based solely on Deaths Per Capita")
 
knitr::kable(table(pred_glm_01, test_oo$Opioid.Prescriber), "pipe", caption = "Confusion Matrix")
```
The last fit to predict the Opioid.Prescriber column I did for the data that included the opioid drugs had the best accuracy of the project.  I fitted the data with only using the drug columns and got a 92% prediction accuracy.  This high number could be due to the fact that the prescriber column is whether a medical professional prescribed more than 10 opioids in a year. 

```{r, include=FALSE}
fit_glm <- glm(Opioid.Prescriber ~ .-deaths.per.cap  - Specialty ,data = train_oo, family = "binomial")
summary(fit_glm)
```

```{r,  include=FALSE}
pred_glm <- predict(fit_glm, test_oo[, -14])
pred_glm_01 <- ifelse(pred_glm > .5, 1, 0)
glm_rmse <- (mean((pred_glm_01 - test_oo$Opioid.Prescriber)^2))^.5
glm_accuracy <- mean(pred_glm_01 == test_oo$Opioid.Prescriber)
glm_opioid3 <- data.frame(glm_accuracy,glm_rmse)
```

```{r, echo=FALSE}
knitr::kable(glm_opioid3, "pipe", caption = "Opioid Data Predictions with only the drugs")
 
knitr::kable(table(pred_glm_01, test_oo$Opioid.Prescriber), "pipe", caption = "Confusion Matrix")


```
 The last fit I did with the data that included the opioids and deaths per capita was to use the data to predict the deaths per capita.  I could not easily get accuracy for deaths per cap estimate since I would need to pick how much to round the data which would change its accuracy, so I only show RMSE. One of the reasons I could have such a low RMSE for calculated deaths per capita is that they are the same for every state. I hoped to counteract this problem by only predicting it based off of specialty and the drug columns. Based on the RMSE value I calculated I can concluded that this model was very successful at predicting the deaths per capita so I think adding this column to the data was a good decision overall.  

```{r, include=FALSE}
fit_glm <- glm(deaths.per.cap ~ . - State- Deaths - Population,data = train_oo)
#summary(fit_glm)
```

```{r, echo=FALSE}
pred_glm <- predict(fit_glm, test_oo[,-17])
glm_accuracy_dpc <- mean(pred_glm == test_oo$deaths.per.cap)
glm_rmse <- (mean((pred_glm - test_oo$deaths.per.cap)^2))^.5

glm_rmse
```




```{r, include=FALSE}
#this is the training and testing for the data without opioid drugs
train <- sample(nrow(no_opioids), nrow(no_opioids)*.7)
test <- no_opioids[-train, ]
train <- no_opioids[train, ]

#test[,242]
```

The first fit I did with the data that did not include the opioid drugs was with the whole data set and I achieved a prediction accuracy of 80%. Its not surprising that this model is not as accurate as the one with the opioid drugs but I was still impressed with how well it did.  When looking at the next model where I only used the non opioid drugs I can see that it has a similar prediction accuracy as the fit with only the specialty column.  This tells me that both the Specialty column and the drugs columns have decent predctions on their own but produce a much more accurate fit when joined together.  

```{r, include=FALSE}
fit_glm <- glm(Opioid.Prescriber ~ ., data = train, family = "binomial")
#summary(fit_glm)
```

```{r, echo=FALSE}
pred_glm <- predict(fit_glm, test[, -242])
pred_glm_01 <- ifelse(pred_glm > .5, 1, 0)
glm_rmse <- (mean((pred_glm_01 - test$Opioid.Prescriber)^2))^.5
glm_accuracy <- mean(pred_glm_01 == test$Opioid.Prescriber)
glm_no_opioid1 <- data.frame(glm_accuracy,glm_rmse)





knitr::kable(glm_no_opioid1, "pipe", caption = "No Opioid drugs Data Predictions with whole dataset")
 
knitr::kable(table(pred_glm_01, test$Opioid.Prescriber), "pipe", caption = "Confusion Matrix")
```


```{r, include=FALSE}
fit_glm <- glm(Opioid.Prescriber ~ . - Specialty,data = train, family = "binomial")
#summary(fit_glm)
```

```{r, echo=FALSE}
pred_glm <- predict(fit_glm, test[, -242])
pred_glm_01 <- ifelse(pred_glm > .5, 1, 0)
glm_accuracy <- mean(pred_glm_01 == test$Opioid.Prescriber)
glm_rmse <- (mean((pred_glm_01 - test_oo$Opioid.Prescriber)^2))^.5
glm_no_opioid2 <- data.frame(glm_accuracy,glm_rmse)

knitr::kable(glm_no_opioid2, "pipe", caption = "No Opioid drugs Data Predictions with whole dataset")
 
knitr::kable(table(pred_glm_01, test$Opioid.Prescriber), "pipe", caption = "Confusion Matrix")
```
## Lasso and Ridge Regression

For this section of the project I did a ridge and lasso regression for each of the data sets to see if there was a difference in choosing the data with the opioid drugs or the one without them. I also wanted to see whether lasso or ridge worked better to see if there were many columns that had a large affect, meaning ridge regression would perform better or the opposite.  I found that for both data sets ridge gave a higher prediction accuracy meaning that no one column had an overwhelming affect when predicting the perscriber column.  

```{r, echo=FALSE}


grid <- 10^seq(-2,10,length = 100)

test_matrix <- model.matrix(Opioid.Prescriber ~ . , data = test)
train_matrix <- model.matrix(Opioid.Prescriber ~ . , data = train)

cv.ridge <- cv.glmnet(train_matrix, train$Opioid.Prescriber, alpha = 0, lambda = grid)

min.ridge <- cv.ridge$cvm[cv.ridge$lambda==cv.ridge$lambda.min]
plot(cv.ridge)


cv.lasso <- cv.glmnet(train_matrix, train$Opioid.Prescriber, alpha = 1,lambda = grid)

min.lasso <- cv.lasso$cvm[cv.lasso$lambda == cv.lasso$lambda.min] 
plot(cv.lasso)




ridge_rmse <- sqrt(min.ridge)
lasso_rmse <- sqrt(min.lasso)



ridge_pred <- predict(cv.ridge, s = cv.ridge$lambda.min, newx = test_matrix)
ridge_pred_matrix <- matrix(ridge_pred)


lasso_pred <- predict(cv.lasso, s = cv.lasso$lambda.min, newx = test_matrix)
lasso_pred_matrix <- matrix(lasso_pred)
```
These graphs show that a lower gamma is the best choice for both lasso and ridge regression models. In the lasso model the mean square error goes up very quickly as gamma increases compared to the ridge regression plot that shows a more gradual increase in MSE as gamma increased.  
```{r, echo=FALSE}
lasso_pred_01 <- ifelse(lasso_pred > .5, 1, 0)
ridge_pred_01 <- ifelse(ridge_pred > .5, 1, 0)

lasso_accuracy <- mean(lasso_pred_01 == test$Opioid.Prescriber)
ridge_accuracy <- mean(ridge_pred_01 == test$Opioid.Prescriber)




rl_preds <- data.frame(lasso_accuracy,ridge_accuracy,ridge_rmse,lasso_rmse)

knitr::kable(rl_preds, "pipe", caption = "Ridge and Lasoo regressions for No Opioid Data")
```

```{r, echo=FALSE}


grid <- 10^seq(-2,10,length = 100)

test_matrix <- model.matrix(Opioid.Prescriber ~ . , data = test_oo)
train_matrix <- model.matrix(Opioid.Prescriber ~ . , data = train_oo)

cv.ridge <- cv.glmnet(train_matrix, train_oo$Opioid.Prescriber, alpha = 0, lambda = grid)

min.ridge <- cv.ridge$cvm[cv.ridge$lambda==cv.ridge$lambda.min]
plot(cv.ridge)


cv.lasso <- cv.glmnet(train_matrix, train_oo$Opioid.Prescriber, alpha = 1,lambda = grid)

min.lasso <- cv.lasso$cvm[cv.lasso$lambda == cv.lasso$lambda.min] 
plot(cv.lasso)



ridge_rmse <- sqrt(min.ridge)



lasso_rmse<- sqrt(min.lasso)




ridge_pred <- predict(cv.ridge, s = cv.ridge$lambda.min, newx = test_matrix)
ridge_pred_matrix <- matrix(ridge_pred)


lasso_pred <- predict(cv.lasso, s = cv.lasso$lambda.min, newx = test_matrix)
lasso_pred_matrix <- matrix(lasso_pred)
```

```{r, echo=FALSE}
lasso_pred_01 <- ifelse(lasso_pred > .5, 1, 0)
ridge_pred_01 <- ifelse(ridge_pred > .5, 1, 0)

lasso_accuracy <- mean(lasso_pred_01 == test_oo$Opioid.Prescriber)
ridge_accuracy <- mean(ridge_pred_01 == test_oo$Opioid.Prescriber)




rl_preds <- data.frame(lasso_accuracy,ridge_accuracy,ridge_rmse,lasso_rmse)

knitr::kable(rl_preds, "pipe", caption = "Ridge and Lasoo regressions for Opioid Data")


```
## Results

Over the course of this project I found that the GLM model performed very well. Even though I did not do as well as a job cleaning the data as the project on kaggle I had prediction accuracy that were not much worse. I was surprised at how well my model did a predicting the deaths per capita, having the lowest RMSE by far than the rest of the project.  If I had more time to continue this project I would like to see If I could clean my data differently so get better accuracy and predict different aspects of the data than solely the Opioid perscriber.  I think that we can use data like this to help find the root of the opioid epidemic and hopefully help put an end to it.



